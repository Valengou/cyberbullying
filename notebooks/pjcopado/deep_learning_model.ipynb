{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794d2ecf",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af27a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9829baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense, Masking\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ab2ad",
   "metadata": {},
   "source": [
    "Check si corre en Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afac6c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    DRIVE = True\n",
    "    from google.colab import files\n",
    "except ModuleNotFoundError:\n",
    "    DRIVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ecba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DRIVE:\n",
    "    #from google.colab import drive\n",
    "    #drive.mount('/content/drive')\n",
    "    #uploaded = files.upload()\n",
    "    #for fn in uploaded.keys():\n",
    "    #    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "    #        name=fn, length=len(uploaded[fn])))\n",
    "    data = pd.read_csv('data.csv')\n",
    "else:\n",
    "    data = pd.read_csv('../../cyberbullying/data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead30984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this: :one can make an analogy in mathematical...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>`  :clarification for you  (and zundark's righ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elected or electoral? jhk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>`this is such a fun entry.   devotchka  i once...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>please relate the ozone hole to increases in c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  this: :one can make an analogy in mathematical...       0\n",
       "1  `  :clarification for you  (and zundark's righ...       0\n",
       "2                          elected or electoral? jhk       0\n",
       "3  `this is such a fun entry.   devotchka  i once...       0\n",
       "4  please relate the ozone hole to increases in c...       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']=data['text'].astype(str)\n",
    "data.loc[:,'target'] = pd.to_numeric(data.loc[:,'target'], downcast='integer')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5203f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(percentage_of_sentences=None):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data['text'],data['target'],test_size=0.3,random_state=0)\n",
    "    \n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "        \n",
    "        len_train = int(percentage_of_sentences/100*len(X_train))\n",
    "        X_train, y_train = X_train[:len_train], y_train[:len_train]\n",
    "  \n",
    "        len_test = int(percentage_of_sentences/100*len(X_test))\n",
    "        X_test, y_test = X_test[:len_test], y_test[:len_test]\n",
    "    \n",
    "    #X_train = [text_to_word_sequence(_) for _ in X_train]\n",
    "    #X_test = [text_to_word_sequence(_) for _ in X_test]\n",
    "    \n",
    "    X_train = X_train.map(text_to_word_sequence)\n",
    "    X_test = X_test.map(text_to_word_sequence)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(percentage_of_sentences=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3ae89",
   "metadata": {},
   "source": [
    "### Balanceo el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b11a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(X, y, ratio=0.3):\n",
    "    df = pd.DataFrame({'text': X_train, 'target': y_train})\n",
    "    df_class_0 = df[df['target'] == 0]\n",
    "    df_class_1 = df[df['target'] == 1]\n",
    "    df_class_1_len = df_class_1.shape[0]\n",
    "    \n",
    "    df_class_0_new = df_class_0.sample(int(df_class_1_len * (1-ratio)/ratio))\n",
    "    df_new = pd.concat([df_class_0_new, df_class_1]).sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    X = df_new['text']\n",
    "    y = df_new['target']\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = balance_df(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a096ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of your embedding space = size to represent each word\n",
    "embedding_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62bb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DRIVE:\n",
    "    word2vec = Word2Vec(sentences=X_train, size=embedding_size, window=5, min_count=5) # colab\n",
    "else:\n",
    "    word2vec = Word2Vec(sentences=X_train, vector_size=embedding_size, window=5, min_count=5) # jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15dc56cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cunt', 0.8905279040336609),\n",
       " ('idiot', 0.8625967502593994),\n",
       " ('motherfucker', 0.8594926595687866),\n",
       " ('retard', 0.8496772646903992),\n",
       " ('prick', 0.8363613486289978),\n",
       " ('fucking', 0.8290894031524658),\n",
       " ('loser', 0.8249950408935547),\n",
       " ('retarded', 0.8243739008903503),\n",
       " ('bitch', 0.8214358687400818),\n",
       " ('faggot', 0.820199191570282)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_1 = word2vec.wv.most_similar('asshole')\n",
    "comm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a8c7a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DRIVE:\n",
    "    vocab_size = len(word2vec.wv.vocab.keys()) # colab\n",
    "else:\n",
    "    vocab_size = len(word2vec.wv.key_to_index) # jupyter\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e447c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1086486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_hist(X):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
    "    len_ = [len(_) for _ in X]\n",
    "    ax1.hist(len_)\n",
    "    ax1.set_title('All length')\n",
    "    \n",
    "    len_2 = [len(_) for _ in X if len(_) < 300]\n",
    "    ax2.hist(len_2)\n",
    "    ax2.set_title('Only length < 300')\n",
    "    \n",
    "    plt.suptitle('Histogram of the number of sentences that have a given number of words')\n",
    "    plt.tight_layout(pad=1)\n",
    "    plt.show()\n",
    "    \n",
    "plot_hist(X_train_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf560ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the training and test embedded sentences\n",
    "maxlen = 100\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e7cfab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63586, 100, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cd7ea01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68847, 100, 32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90f542f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ME\n",
    "for X in [X_train_pad, X_test_pad]:\n",
    "    assert type(X) == np.ndarray\n",
    "    assert X.shape[-1] == word2vec.wv.vector_size\n",
    "\n",
    "\n",
    "assert X_train_pad.shape[0] == len(X_train)\n",
    "assert X_test_pad.shape[0] == len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9a1fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (maxlen,embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0589b66c",
   "metadata": {},
   "source": [
    "# Deep Learning Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e7aebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "057c6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(result):\n",
    "    for metric, value in zip(['Loss', 'Accuracy', 'Recall', 'Precision'], result):\n",
    "        print(f'{metric}: {value:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965957c",
   "metadata": {},
   "source": [
    "## SimpleRNN Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c011ce52",
   "metadata": {},
   "source": [
    "def init_model_rnn():\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Masking(mask_value=0, input_shape=input_shape))\n",
    "    \n",
    "    model.add(SimpleRNN(20, activation='tanh'))\n",
    "    \n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=Recall())\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_rnn = init_model_rnn()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d2c3fdb",
   "metadata": {},
   "source": [
    "%%time\n",
    "history_rnn = model_rnn.fit(X_train_pad, y_train, validation_split=0.3, callbacks=es, verbose=1, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71595fbf",
   "metadata": {},
   "source": [
    "res_rnn = model_rnn.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f'The recall evaluated on the test set is of {res_rnn[1]*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68435939",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d68680ce",
   "metadata": {},
   "source": [
    "def init_model_lstm():\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Masking(mask_value=0, input_shape=input_shape))\n",
    "    \n",
    "    model.add(LSTM(20, activation='tanh'))\n",
    "    \n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=Recall())\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_lstm = init_model_lstm()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebd541ef",
   "metadata": {},
   "source": [
    "%%time\n",
    "history_lstm = model_lstm.fit(X_train_pad, y_train, validation_split=0.3, callbacks=es, verbose=1, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f33c6cf7",
   "metadata": {},
   "source": [
    "res_lstm = model_lstm.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f'The recall evaluated on the test set is of {res_lstm[1]*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352f756",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73fc7541",
   "metadata": {},
   "source": [
    "def init_model_gru():\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Masking(mask_value=0, input_shape=input_shape))\n",
    "    \n",
    "    model.add(LSTM(20, activation='tanh'))\n",
    "    \n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=Recall())\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_gru = init_model_gru()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79f6c802",
   "metadata": {},
   "source": [
    "%%time\n",
    "history_gru = model_gru.fit(X_train_pad, y_train, validation_split=0.3, callbacks=es, verbose=1, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "475491b2",
   "metadata": {},
   "source": [
    "res_gru = model_gru.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f'The recall evaluated on the test set is of {res_gru[1]*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318317f",
   "metadata": {},
   "source": [
    "Best base model: GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de38d5",
   "metadata": {},
   "source": [
    "## Tunning GRU Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707731c",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a692787",
   "metadata": {},
   "source": [
    "def init_model_gru_2():\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Masking(mask_value=0, input_shape=input_shape))\n",
    "    \n",
    "    model.add(LSTM(32, activation='tanh'))\n",
    "    \n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=Recall())\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_gru_2 = init_model_gru_2()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96ed247d",
   "metadata": {},
   "source": [
    "%%time\n",
    "history_gru_2 = model_gru_2.fit(X_train_pad, y_train, validation_split=0.3, callbacks=es, verbose=1, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7621e950",
   "metadata": {},
   "source": [
    "res_gru_2 = model_gru_2.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f'The recall evaluated on the test set is of {res_gru_2[1]*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9131d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 21:39:36.241765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-08 21:39:36.244754: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-08 21:39:36.245376: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-08 21:39:36.246110: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 100, 32)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 16)                3136      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                170       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,317\n",
      "Trainable params: 3,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def init_model_gru_3():\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Masking(mask_value=0, input_shape=input_shape))\n",
    "    \n",
    "    model.add(LSTM(16, activation='tanh'))\n",
    "    \n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy', Recall(), Precision()])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_gru_3 = init_model_gru_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c1e394b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "696/696 [==============================] - 49s 66ms/step - loss: 0.3984 - accuracy: 0.8180 - recall: 0.6614 - precision: 0.7126 - val_loss: 0.3478 - val_accuracy: 0.8480 - val_recall: 0.7029 - val_precision: 0.7683\n",
      "Epoch 2/100\n",
      "696/696 [==============================] - 45s 65ms/step - loss: 0.3359 - accuracy: 0.8486 - recall: 0.7183 - precision: 0.7640 - val_loss: 0.3232 - val_accuracy: 0.8583 - val_recall: 0.7475 - val_precision: 0.7709\n",
      "Epoch 3/100\n",
      "696/696 [==============================] - 43s 62ms/step - loss: 0.3193 - accuracy: 0.8562 - recall: 0.7341 - precision: 0.7755 - val_loss: 0.3141 - val_accuracy: 0.8612 - val_recall: 0.7651 - val_precision: 0.7688\n",
      "Epoch 4/100\n",
      "696/696 [==============================] - 42s 61ms/step - loss: 0.3106 - accuracy: 0.8610 - recall: 0.7423 - precision: 0.7840 - val_loss: 0.3091 - val_accuracy: 0.8639 - val_recall: 0.7032 - val_precision: 0.8154\n",
      "Epoch 5/100\n",
      "696/696 [==============================] - 43s 61ms/step - loss: 0.3040 - accuracy: 0.8640 - recall: 0.7484 - precision: 0.7885 - val_loss: 0.3022 - val_accuracy: 0.8676 - val_recall: 0.7406 - val_precision: 0.8008\n",
      "Epoch 6/100\n",
      "696/696 [==============================] - 43s 61ms/step - loss: 0.2985 - accuracy: 0.8671 - recall: 0.7546 - precision: 0.7934 - val_loss: 0.3036 - val_accuracy: 0.8674 - val_recall: 0.7150 - val_precision: 0.8180\n",
      "Epoch 7/100\n",
      "696/696 [==============================] - 45s 65ms/step - loss: 0.2942 - accuracy: 0.8693 - recall: 0.7570 - precision: 0.7978 - val_loss: 0.3023 - val_accuracy: 0.8675 - val_recall: 0.7108 - val_precision: 0.8213\n",
      "Epoch 8/100\n",
      "696/696 [==============================] - 44s 63ms/step - loss: 0.2914 - accuracy: 0.8712 - recall: 0.7605 - precision: 0.8009 - val_loss: 0.2981 - val_accuracy: 0.8705 - val_recall: 0.7475 - val_precision: 0.8049\n",
      "Epoch 9/100\n",
      "696/696 [==============================] - 42s 60ms/step - loss: 0.2883 - accuracy: 0.8734 - recall: 0.7643 - precision: 0.8047 - val_loss: 0.2959 - val_accuracy: 0.8710 - val_recall: 0.7810 - val_precision: 0.7857\n",
      "Epoch 10/100\n",
      "696/696 [==============================] - 42s 60ms/step - loss: 0.2848 - accuracy: 0.8748 - recall: 0.7648 - precision: 0.8083 - val_loss: 0.2981 - val_accuracy: 0.8696 - val_recall: 0.8130 - val_precision: 0.7650\n",
      "Epoch 11/100\n",
      "696/696 [==============================] - 41s 60ms/step - loss: 0.2829 - accuracy: 0.8762 - recall: 0.7725 - precision: 0.8073 - val_loss: 0.2963 - val_accuracy: 0.8744 - val_recall: 0.7503 - val_precision: 0.8145\n",
      "Epoch 12/100\n",
      "696/696 [==============================] - 42s 60ms/step - loss: 0.2801 - accuracy: 0.8778 - recall: 0.7704 - precision: 0.8131 - val_loss: 0.2954 - val_accuracy: 0.8752 - val_recall: 0.7600 - val_precision: 0.8103\n",
      "Epoch 13/100\n",
      "696/696 [==============================] - 42s 60ms/step - loss: 0.2782 - accuracy: 0.8777 - recall: 0.7741 - precision: 0.8107 - val_loss: 0.3006 - val_accuracy: 0.8692 - val_recall: 0.8084 - val_precision: 0.7663\n",
      "Epoch 14/100\n",
      "696/696 [==============================] - 41s 60ms/step - loss: 0.2763 - accuracy: 0.8780 - recall: 0.7748 - precision: 0.8109 - val_loss: 0.2953 - val_accuracy: 0.8735 - val_recall: 0.7421 - val_precision: 0.8173\n",
      "Epoch 15/100\n",
      "696/696 [==============================] - 41s 59ms/step - loss: 0.2743 - accuracy: 0.8794 - recall: 0.7779 - precision: 0.8129 - val_loss: 0.3062 - val_accuracy: 0.8621 - val_recall: 0.8344 - val_precision: 0.7380\n",
      "Epoch 16/100\n",
      "696/696 [==============================] - 41s 59ms/step - loss: 0.2726 - accuracy: 0.8795 - recall: 0.7794 - precision: 0.8122 - val_loss: 0.3002 - val_accuracy: 0.8713 - val_recall: 0.8135 - val_precision: 0.7688\n",
      "Epoch 17/100\n",
      "696/696 [==============================] - 42s 60ms/step - loss: 0.2710 - accuracy: 0.8804 - recall: 0.7806 - precision: 0.8140 - val_loss: 0.2939 - val_accuracy: 0.8726 - val_recall: 0.7510 - val_precision: 0.8087\n",
      "Epoch 18/100\n",
      "696/696 [==============================] - 43s 62ms/step - loss: 0.2695 - accuracy: 0.8818 - recall: 0.7822 - precision: 0.8169 - val_loss: 0.3025 - val_accuracy: 0.8691 - val_recall: 0.7076 - val_precision: 0.8287\n",
      "Epoch 19/100\n",
      "696/696 [==============================] - 43s 61ms/step - loss: 0.2677 - accuracy: 0.8818 - recall: 0.7818 - precision: 0.8171 - val_loss: 0.3107 - val_accuracy: 0.8653 - val_recall: 0.8328 - val_precision: 0.7458\n",
      "Epoch 20/100\n",
      "696/696 [==============================] - 43s 62ms/step - loss: 0.2668 - accuracy: 0.8829 - recall: 0.7866 - precision: 0.8170 - val_loss: 0.2937 - val_accuracy: 0.8722 - val_recall: 0.7745 - val_precision: 0.7926\n",
      "Epoch 21/100\n",
      "696/696 [==============================] - 41s 59ms/step - loss: 0.2651 - accuracy: 0.8841 - recall: 0.7857 - precision: 0.8211 - val_loss: 0.2953 - val_accuracy: 0.8728 - val_recall: 0.7833 - val_precision: 0.7891\n",
      "Epoch 22/100\n",
      "696/696 [==============================] - 43s 62ms/step - loss: 0.2637 - accuracy: 0.8837 - recall: 0.7891 - precision: 0.8176 - val_loss: 0.2970 - val_accuracy: 0.8714 - val_recall: 0.7982 - val_precision: 0.7770\n",
      "Epoch 23/100\n",
      "696/696 [==============================] - 41s 59ms/step - loss: 0.2629 - accuracy: 0.8844 - recall: 0.7904 - precision: 0.8188 - val_loss: 0.2964 - val_accuracy: 0.8725 - val_recall: 0.7770 - val_precision: 0.7919\n",
      "Epoch 24/100\n",
      "696/696 [==============================] - 42s 60ms/step - loss: 0.2612 - accuracy: 0.8857 - recall: 0.7906 - precision: 0.8224 - val_loss: 0.3063 - val_accuracy: 0.8704 - val_recall: 0.7180 - val_precision: 0.8252\n",
      "Epoch 25/100\n",
      "696/696 [==============================] - 42s 61ms/step - loss: 0.2602 - accuracy: 0.8858 - recall: 0.7907 - precision: 0.8224 - val_loss: 0.2984 - val_accuracy: 0.8719 - val_recall: 0.7821 - val_precision: 0.7873\n",
      "CPU times: user 52min 52s, sys: 28min 27s, total: 1h 21min 20s\n",
      "Wall time: 17min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_gru_3 = model_gru_3.fit(X_train_pad, y_train, validation_split=0.3, callbacks=es, verbose=1, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da92c889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  12/2152 [..............................] - ETA: 21s - loss: 0.2984 - accuracy: 0.8333 - recall: 0.6286 - precision: 0.3014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 21:57:24.853507: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 881241600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2152/2152 [==============================] - 22s 10ms/step - loss: 0.2406 - accuracy: 0.8952 - recall: 0.7633 - precision: 0.5434\n"
     ]
    }
   ],
   "source": [
    "res_gru_3 = model_gru_3.evaluate(X_test_pad, y_test, verbose=1)\n",
    "print_metrics(res_gru_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b08df4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.24\n",
      "Accuracy: 0.90\n",
      "Recall: 0.76\n",
      "Precision: 0.54\n"
     ]
    }
   ],
   "source": [
    "print_metrics(res_gru_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d4d0244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 23:17:36.873060: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://0f027b57-59bf-4634-941d-ada9bc526e54/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://0f027b57-59bf-4634-941d-ada9bc526e54/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9d818e4b50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_gru_3.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_gru_3, 'model_gru_3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4959a249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
