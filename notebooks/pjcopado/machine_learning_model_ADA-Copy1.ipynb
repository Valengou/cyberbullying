{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb494e4",
   "metadata": {},
   "source": [
    "# Modelos de Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d121970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, make_scorer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import joblib\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix\n",
    "\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7b1a8",
   "metadata": {},
   "source": [
    "## Importamos el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdc41a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beepss senna beepss i m not sexist but fuck if...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no you don t shut up jeff i thought of a reall...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wateronatrain mt you might like this http t co...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>metalbarbiedoll but yea apparently gamergate w...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d nkrause dudes who go to culinary school why ...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    type\n",
       "0  beepss senna beepss i m not sexist but fuck if...  gender\n",
       "1  no you don t shut up jeff i thought of a reall...  gender\n",
       "2  wateronatrain mt you might like this http t co...  gender\n",
       "3  metalbarbiedoll but yea apparently gamergate w...  gender\n",
       "4  d nkrause dudes who go to culinary school why ...  gender"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lem = pd.read_csv('../../cyberbullying/data/lem_classified_racism_tweets.csv')\n",
    "df_lem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618a788f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42270, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6214b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_used = 1\n",
    "df_sample = df_lem.sample(frac=percentage_used, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d7e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_enc=LabelEncoder()\n",
    "df_sample['encoded_type']=label_enc.fit_transform(df_sample['type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3527ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>encoded_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16954</th>\n",
       "      <td>idiot koomuttai there are lakhs of temples in ...</td>\n",
       "      <td>religion</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20206</th>\n",
       "      <td>miyata kurisu all of us right now</td>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30032</th>\n",
       "      <td>nobody tells you that high school is harder th...</td>\n",
       "      <td>age</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>making jokes about rape huh disgusting go fuck...</td>\n",
       "      <td>gender</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35664</th>\n",
       "      <td>a white teenager called both negro and the n word</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41993</th>\n",
       "      <td>you lazy dumb niggers have had s of years to g...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103</th>\n",
       "      <td>i m not for victims of bullying going crazy an...</td>\n",
       "      <td>age</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>instead they think having games of foot ball i...</td>\n",
       "      <td>age</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>hagusp gabriella t i fucking know i was like w...</td>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>from zero to cunt in eight seconds too bad tha...</td>\n",
       "      <td>gender</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42270 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text       type  \\\n",
       "16954  idiot koomuttai there are lakhs of temples in ...   religion   \n",
       "20206                  miyata kurisu all of us right now      other   \n",
       "30032  nobody tells you that high school is harder th...        age   \n",
       "8522   making jokes about rape huh disgusting go fuck...     gender   \n",
       "35664  a white teenager called both negro and the n word  ethnicity   \n",
       "...                                                  ...        ...   \n",
       "41993  you lazy dumb niggers have had s of years to g...  ethnicity   \n",
       "32103  i m not for victims of bullying going crazy an...        age   \n",
       "30403  instead they think having games of foot ball i...        age   \n",
       "21243  hagusp gabriella t i fucking know i was like w...      other   \n",
       "2732   from zero to cunt in eight seconds too bad tha...     gender   \n",
       "\n",
       "       encoded_type  \n",
       "16954             4  \n",
       "20206             3  \n",
       "30032             0  \n",
       "8522              2  \n",
       "35664             1  \n",
       "...             ...  \n",
       "41993             1  \n",
       "32103             0  \n",
       "30403             0  \n",
       "21243             3  \n",
       "2732              2  \n",
       "\n",
       "[42270 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766bf6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'ethnicity', 'gender', 'other', 'religion'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels=label_enc.classes_\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44d0c3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9832\n",
       "2    8825\n",
       "4    7982\n",
       "0    7956\n",
       "3    7675\n",
       "Name: encoded_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['encoded_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5a5f6",
   "metadata": {},
   "source": [
    "## Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cf99c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_sample['text'], df_sample['encoded_type'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1059a0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12185    dankmtl peacenothate she does to the idf hamas...\n",
       "28501    this is what happens when you go through high ...\n",
       "32002    u bully one white kid in ur school s christian...\n",
       "7001     yeah the show is horrible comedy you can t rel...\n",
       "38246    how to deal with dumb niggers like you qt nbe ...\n",
       "                               ...                        \n",
       "2195     jaykyew call me sexist but hearing a woman do ...\n",
       "35252    i do wish you wouldn t cherry pick a tweet lik...\n",
       "6451     gross ronaldinho has come out fiercely in supp...\n",
       "5345     you never saw any celebrity say anything like ...\n",
       "3102     doublebirdexit this lady is a terrible officia...\n",
       "Name: text, Length: 29589, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9f49f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68250130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(cv_results):\n",
    "    score_results = {'accuracy': None, 'precision': None, 'recall': None, 'f1': None, 'time': None}\n",
    "    for key in score_results.keys():\n",
    "        if key == 'time':\n",
    "            score_results[key] = round(cv_results['fit_time'].mean() + cv_results['score_time'].mean(), 1)\n",
    "        else:\n",
    "            score_results[key] = round(cv_results[f'test_{key}'].mean(), 4)\n",
    "    return score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ace33a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mx_all(y_test, y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    TN = cm[0,0]\n",
    "    TP = cm[1,1]\n",
    "    FN = cm[1,0]\n",
    "    FP = cm[0,1]\n",
    "    \n",
    "    recall = np.round_(TP/(TP+FN),3)\n",
    "    precision = np.round_(TP/(TP+FP),3)\n",
    "    accuracy = np.round_((TP+TN)/(TP+TN+FP+FN),3)\n",
    "    F1= np.round((2*precision*recall)/(precision+recall), 3)\n",
    "    \n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1-score: {F1}\")\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[0,1])\n",
    "    disp.plot();\n",
    "    \n",
    "    return recall, precision, accuracy, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47457409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(vectorizer_list, learner_list, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    def list_params(new_class):\n",
    "        name = new_class.__class__.__name__\n",
    "        default_class = eval(name + '()').get_params()\n",
    "        new_class = new_class.get_params()\n",
    "\n",
    "        new_dict = {}\n",
    "\n",
    "        for key in new_class.keys():\n",
    "            if new_class[key] != default_class[key]:\n",
    "                new_dict[key] = new_class[key]\n",
    "        return new_dict\n",
    "    \n",
    "    \n",
    "    # Get length of Training Data:\n",
    "    size = len(y_train)\n",
    "    \n",
    "    results = {}\n",
    "    final_results = []\n",
    "    \n",
    "    for vectorizer in vectorizer_list:\n",
    "        \n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "        \n",
    "    \n",
    "        for learner in learner_list:\n",
    "        \n",
    "            # Store the learner name:\n",
    "            results['Algorithm'] = learner.__class__.__name__\n",
    "\n",
    "            # Fit the learner:\n",
    "            start = time() # Get start time\n",
    "            print(\"Training {}\".format(learner.__class__.__name__))\n",
    "            learner = learner.fit(X_train_vec, y_train)\n",
    "            end = time() # Get end time\n",
    "\n",
    "            # Store the training time\n",
    "            results['Training Time'] = end - start\n",
    "\n",
    "            start = time() # Get start time\n",
    "            predictions_test = learner.predict(X_test_vec)\n",
    "            predictions_train = learner.predict(X_train_vec)\n",
    "            end = time() # Get end time\n",
    "\n",
    "            # Store the prediction time\n",
    "            results['Prediction Time'] = end - start\n",
    "\n",
    "            results['Metrics: Test']=classification_report(y_test, predictions_test, target_names=label_enc.classes_)\n",
    "            results['Metrics: Train']=classification_report(y_train, predictions_train, target_names=label_enc.classes_)\n",
    "\n",
    "            # Compute the Accuracy on Test Set\n",
    "            #results['Accuracy: Test'] = accuracy_score(y_test, predictions_test)\n",
    "\n",
    "            # Compute the Accuracy on Training Set\n",
    "            #results['Accuracy: Train'] = accuracy_score(y_train, predictions_train)\n",
    "\n",
    "            # Compute the F1 Score on Test Set\n",
    "            #results['F1 Score: Test'] = f1_score(y_test, predictions_test)\n",
    "\n",
    "            # Compute the F1 Score on Training Set\n",
    "            #results['F1 Score: Train'] = f1_score(y_train, predictions_train)\n",
    "\n",
    "            # Compute the Precision on Test Set\n",
    "            #results['Precision: Test'] = precision_score(y_test, predictions_test)\n",
    "\n",
    "            # Compute the Precision on Training Set\n",
    "            #results['Precision: Train'] = precision_score(y_train, predictions_train)\n",
    "\n",
    "            # Compute the Recall on Test Set\n",
    "            #results['Recall: Test'] = recall_score(y_test, predictions_test)\n",
    "\n",
    "            # Compute the Recall on Training Set\n",
    "            #results['Recall: Train'] = recall_score(y_train, predictions_train)\n",
    "\n",
    "            # Success\n",
    "            print(\"Training {} finished in {:.2f} sec\".format(learner.__class__.__name__, results['Training Time']))\n",
    "            print('----------------------------------------------------')\n",
    "\n",
    "            final_results.append(results.copy())\n",
    "    # Return a dataframe of the results\n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ff5f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b3b47a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AdaBoostClassifier\n",
      "Training AdaBoostClassifier finished in 2.31 sec\n",
      "----------------------------------------------------\n",
      "CPU times: user 5.14 s, sys: 1.11 ms, total: 5.14 s\n",
      "Wall time: 5.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make a list of vectorizers\n",
    "vectorizers = [TfidfVectorizer(min_df=10, max_df=0.8, max_features=20000, ngram_range=(1,2))]\n",
    "\n",
    "# make a list of models\n",
    "models = [AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), n_estimators=10),\n",
    "          #XGBClassifier(max_depth=10, n_estimators=100, learning_rate=0.1, use_label_encoder=False)\n",
    "         ] \n",
    "\n",
    "\n",
    "re = pipeline(vectorizers, models, X_train, y_train, X_test, y_test)\n",
    "results = pd.DataFrame(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73aa1c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    AdaBoostClassifier\n",
       "Name: Algorithm, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Algorithm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60d1dc48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.98      0.99      0.98      2427\n",
      "   ethnicity       0.91      0.80      0.85      2913\n",
      "      gender       0.94      0.79      0.86      2652\n",
      "       other       0.71      0.92      0.80      2317\n",
      "    religion       0.85      0.88      0.86      2372\n",
      "\n",
      "    accuracy                           0.87     12681\n",
      "   macro avg       0.88      0.87      0.87     12681\n",
      "weighted avg       0.88      0.87      0.87     12681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results['Metrics: Test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a181dab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Prediction Time</th>\n",
       "      <th>Metrics: Test</th>\n",
       "      <th>Metrics: Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>2.305662</td>\n",
       "      <td>0.094447</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Algorithm  Training Time  Prediction Time  \\\n",
       "0  AdaBoostClassifier       2.305662         0.094447   \n",
       "\n",
       "                                       Metrics: Test  \\\n",
       "0                precision    recall  f1-score   ...   \n",
       "\n",
       "                                      Metrics: Train  \n",
       "0                precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9549fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results['Metrics: Test'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbae1fa",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61880113",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(sentences=X_train, vector_size=32, window=5, min_count=5) # jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ed9e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "#X_train_embed = embedding(word2vec, X_train)\n",
    "#X_test_embed = embedding(word2vec, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77d20f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f678ec6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12185    4\n",
       "28501    0\n",
       "32002    0\n",
       "7001     2\n",
       "38246    1\n",
       "        ..\n",
       "2195     2\n",
       "35252    1\n",
       "6451     2\n",
       "5345     2\n",
       "3102     2\n",
       "Name: encoded_type, Length: 29589, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5000403",
   "metadata": {},
   "source": [
    "model=AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),n_estimators=10)\n",
    "\n",
    "#model.fit(X_train_embed, y_train)\n",
    "\n",
    "\n",
    "predictions_test = model.predict(X_test_embed)\n",
    "predictions_train = model.predict(X_train_embed)\n",
    "\n",
    "\n",
    "results_test=classification_report(y_test, predictions_test, target_names=label_enc.classes_)\n",
    "results_train=classification_report(y_train, predictions_train, target_names=label_enc.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05b1ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(model, type_):\n",
    "    name = model[type_]\n",
    "    params = model[f'{type_} Params']\n",
    "    return eval(f'{name}(**{params})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5e0c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_vectorizer = get_best_model(results.iloc[0], 'Vectorizer')\n",
    "#best_model = get_best_model(results.iloc[0], 'Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8bea9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31c077d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9399afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(results):\n",
    "    score_results = {'class_weight': [dic['class_weight'][0] for dic in results['Algorithm Params'].values],\n",
    "                     'accuracy': results['accuracy'],\n",
    "                     'precision': results['precision'],\n",
    "                     'recall': results['recall'],\n",
    "                     'f1': results['f1'],\n",
    "                     'time': results['Training Time'] + results['Prediction Time']}\n",
    "    \n",
    "    score_results = pd.DataFrame(data=score_results).sort_values(by = 'class_weight').reset_index(drop = True)\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "        \n",
    "    plt.plot(score_results['class_weight'], score_results['recall'], c='r', label='recall')\n",
    "    plt.plot(score_results['class_weight'], score_results['precision'], c='b', label='precision')    \n",
    "    plt.plot(score_results['class_weight'], score_results['f1'], c='g', label='f1')\n",
    "    plt.xlabel('class weight')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "        \n",
    "    #return score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95b3bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_scores(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f9ef0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = best_vectorizer\n",
    "#model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "851ab67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing = make_column_transformer(\n",
    "#    (make_pipeline(vectorizer), 'text')\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e4128aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(\n",
    "#    preprocessing,\n",
    "#    model\n",
    "#)\n",
    "\n",
    "#pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2822ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "916892bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.DataFrame(data=X_train, columns=['text'])\n",
    "#X_test = pd.DataFrame(data=X_test, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca2f8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_results = cross_validate(pipe, X_train, y_train, cv=5, n_jobs=-1, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b331baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1eeacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28344321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e661c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf_mx_all(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17fdb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde6e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06303af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bab0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'columntransformer__pipeline__tfidfvectorizer__min_df': np.arange(5, 11),\n",
    "    'linearsvc__C': np.arange(0.8, 1.3, 0.1),\n",
    "    'linearsvc__class_weight': [{0: weight_0, 1: 1-weight_0} for weight_0 in np.arange(0.17, 0.24, 0.01)]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbd4fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'columntransformer__pipeline__tfidfvectorizer__min_df': np.arange(5, 11),\n",
    "    'linearsvc__C': np.arange(0.9, 1.2, 0.1),\n",
    "    'linearsvc__class_weight': [{0: weight_0, 1: 1-weight_0} for weight_0 in np.arange(0.18, 0.24, 0.01)],\n",
    "    'linearsvc__dual': [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d015f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search = GridSearchCV(pipe, param_grid=params, cv=5, n_jobs=-1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93d64d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Âµs, sys: 1 Âµs, total: 3 Âµs\n",
      "Wall time: 4.05 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca9f3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e86e7b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_estimator = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43f2a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = best_estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ecc3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bd4b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e59e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf_mx_all(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed596e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c6b73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7632896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista = ['you fucking retard', 'asshole', 'stupid bitch', 'hello!',\n",
    "#        \"ns he can use and practice with. I can't say much more coz I don't have more space. Retard. This is all we need an Australian version of 1 Direction.... my dick was bleeding from how hard I was masturbating to this\",\n",
    "#        ]\n",
    "#lista = pd.DataFrame(data=lista, columns=['text'])\n",
    "\n",
    "#best_estimator.predict(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a15a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e87cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb26110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d6d3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_vec = best_vectorizer.fit_transform(X_train['text'])\n",
    "#X_test_vec = best_vectorizer.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "926a0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_threshold(C=1):\n",
    "    score_results = {'class_weight': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'time': []}\n",
    "    \n",
    "    def scores2(cv_results, class_weight):\n",
    "        score_results = {'class_weight': None, 'accuracy': None, 'precision': None, 'recall': None, 'f1': None, 'time': None}\n",
    "        for key in score_results.keys():\n",
    "            if key == 'class_weight':\n",
    "                score_results[key] = class_weight\n",
    "            elif key == 'time':\n",
    "                score_results[key] = round(cv_results['fit_time'].mean() + cv_results['score_time'].mean(), 1)\n",
    "            else:\n",
    "                score_results[key] = round(cv_results[f'test_{key}'].mean(), 4)\n",
    "        return score_results\n",
    "    \n",
    "    for class_weight in np.arange(0.05, 0.3, 0.05):\n",
    "        print(class_weight)\n",
    "        \n",
    "        cv_results = cross_validate(LinearSVC(C=C, class_weight={0:class_weight, 1:1-class_weight}),\n",
    "                                    X_train_vec, y_train, cv=5, n_jobs=-1,\n",
    "                                    scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "        score_results_new = scores2(cv_results, class_weight)\n",
    "        \n",
    "        for key in score_results.keys():\n",
    "            score_results[key].append(score_results_new[key])\n",
    "            \n",
    "        \n",
    "    plt.figure(figsize=(12,6))\n",
    "        \n",
    "    plt.plot(score_results['class_weight'], score_results['recall'], c='r', label='recall')\n",
    "    plt.plot(score_results['class_weight'], score_results['precision'], c='b', label='precision')    \n",
    "    plt.plot(score_results['class_weight'], score_results['f1'], c='g', label='f1')\n",
    "    plt.xlabel('class weight')\n",
    "    plt.ylabel('score')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "        \n",
    "    return score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34e63bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "095283cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune_threshold(C=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b797d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune_threshold(C=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81b4fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune_threshold(C=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a622962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27c64159",
   "metadata": {},
   "source": [
    "# ESTE ES EL MODELO QUE VAMOS A USAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48aee02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10,max_df=0.8,max_features=25000, ngram_range=(1,2),)\n",
    "\n",
    "# make a list of models\n",
    "model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                               n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e67c4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec=vectorizer.fit_transform(X_train)\n",
    "X_test_vec=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60c26959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12185    dankmtl peacenothate she does to the idf hamas...\n",
       "28501    this is what happens when you go through high ...\n",
       "32002    u bully one white kid in ur school s christian...\n",
       "7001     yeah the show is horrible comedy you can t rel...\n",
       "38246    how to deal with dumb niggers like you qt nbe ...\n",
       "                               ...                        \n",
       "2195     jaykyew call me sexist but hearing a woman do ...\n",
       "35252    i do wish you wouldn t cherry pick a tweet lik...\n",
       "6451     gross ronaldinho has come out fiercely in supp...\n",
       "5345     you never saw any celebrity say anything like ...\n",
       "3102     doublebirdexit this lady is a terrible officia...\n",
       "Name: text, Length: 29589, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0df3946a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<29589x12352 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 833570 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "41177a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.31059194, 2.35242295, 2.32735705, 2.31723762, 2.35902762]),\n",
       " 'score_time': array([0.02346015, 0.02383971, 0.0265851 , 0.02820253, 0.02529311]),\n",
       " 'test_score': array([0.85366678, 0.85518756, 0.85147009, 0.86684691, 0.85837418])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = cross_validate(model, X_train_vec, y_train, cv=5, n_jobs=-1)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52b58949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
       "                   n_estimators=10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf53d251",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 3, ..., 4, 4, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test=model.predict(X_test_vec)\n",
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d482f1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         age       0.98      0.99      0.99      2427\n",
      "   ethnicity       0.91      0.80      0.85      2913\n",
      "      gender       0.94      0.79      0.86      2652\n",
      "       other       0.71      0.92      0.80      2317\n",
      "    religion       0.85      0.88      0.86      2372\n",
      "\n",
      "    accuracy                           0.87     12681\n",
      "   macro avg       0.88      0.87      0.87     12681\n",
      "weighted avg       0.88      0.87      0.87     12681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction_test, target_names=label_enc.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c890cf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text            randi at http t co dr fqxkymq\n",
       "type                                    other\n",
       "encoded_type                                3\n",
       "Name: 20479, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=df_sample.iloc[1500]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c0119b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'randi at http t co dr fqxkymq'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5390914a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'other'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec=vectorizer.transform([text['text']])\n",
    "prediction=class_labels[model.predict(text_vec)]\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40e71358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16954</th>\n",
       "      <td>idiot koomuttai there are lakhs of temples in ...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20206</th>\n",
       "      <td>miyata kurisu all of us right now</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30032</th>\n",
       "      <td>nobody tells you that high school is harder th...</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>making jokes about rape huh disgusting go fuck...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35664</th>\n",
       "      <td>a white teenager called both negro and the n word</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41993</th>\n",
       "      <td>you lazy dumb niggers have had s of years to g...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103</th>\n",
       "      <td>i m not for victims of bullying going crazy an...</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>instead they think having games of foot ball i...</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>hagusp gabriella t i fucking know i was like w...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>from zero to cunt in eight seconds too bad tha...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42270 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text       type\n",
       "16954  idiot koomuttai there are lakhs of temples in ...   religion\n",
       "20206                  miyata kurisu all of us right now      other\n",
       "30032  nobody tells you that high school is harder th...        age\n",
       "8522   making jokes about rape huh disgusting go fuck...     gender\n",
       "35664  a white teenager called both negro and the n word  ethnicity\n",
       "...                                                  ...        ...\n",
       "41993  you lazy dumb niggers have had s of years to g...  ethnicity\n",
       "32103  i m not for victims of bullying going crazy an...        age\n",
       "30403  instead they think having games of foot ball i...        age\n",
       "21243  hagusp gabriella t i fucking know i was like w...      other\n",
       "2732   from zero to cunt in eight seconds too bad tha...     gender\n",
       "\n",
       "[42270 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[['text','type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a26f13c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('pipeline',\n",
       "                                                  Pipeline(steps=[('tfidfvectorizer',\n",
       "                                                                   TfidfVectorizer(max_df=0.8,\n",
       "                                                                                   max_features=25000,\n",
       "                                                                                   min_df=10,\n",
       "                                                                                   ngram_range=(1,\n",
       "                                                                                                2)))]),\n",
       "                                                  'text')])),\n",
       "                ('adaboostclassifier',\n",
       "                 AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
       "                                    n_estimators=10))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing = make_column_transformer(\n",
    "    (make_pipeline(vectorizer), 'text')\n",
    ")\n",
    "\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    preprocessing,\n",
    "    model\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d002c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d83fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
